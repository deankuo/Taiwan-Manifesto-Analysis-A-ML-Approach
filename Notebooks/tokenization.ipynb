{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 11:01:50.698634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/deankuo/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "2024-04-25 11:02:00.986005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 11:02:01.035084: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "/Users/deankuo/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Users/deankuo/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4199\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Pack'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m CKIP_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../CKIP_TAGGER\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m ws \u001b[38;5;241m=\u001b[39m WS(CKIP_PATH) \u001b[38;5;66;03m# 斷詞\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mPOS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCKIP_PATH\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 詞性標註\u001b[39;00m\n\u001b[1;32m     30\u001b[0m ner \u001b[38;5;241m=\u001b[39m NER(CKIP_PATH)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/api.py:172\u001b[0m, in \u001b[0;36mPOS.__init__\u001b[0;34m(self, data_dir, disable_cuda)\u001b[0m\n\u001b[1;32m    169\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGraph()\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 172\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     model\u001b[38;5;241m.\u001b[39msess \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m    174\u001b[0m     model\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglobal_variables_initializer())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_pos.py:172\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_hyper_parameter(config)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_embedding()\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_classifier()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ckiptagger/model_pos.py:205\u001b[0m, in \u001b[0;36mModel.create_encoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m s_l_max \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_v)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Character\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m c_known     \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mequal(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ms_l_max\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m)                         \u001b[38;5;66;03m# [batch*s_l_max]\u001b[39;00m\n\u001b[1;32m    206\u001b[0m c_known_v   \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_v, [batch\u001b[38;5;241m*\u001b[39ms_l_max, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_embedding_d\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_feature_d]) \u001b[38;5;66;03m# [batch*s_l_max, c_embedding_d+c_feature_d]\u001b[39;00m\n\u001b[1;32m    207\u001b[0m c_unknown_v \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munknown_c_v, [batch\u001b[38;5;241m*\u001b[39ms_l_max, \u001b[38;5;241m1\u001b[39m])                              \u001b[38;5;66;03m# [batch*s_l_max, c_embedding_d+c_feature_d]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:199\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m   tensor_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:8551\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8549\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   8550\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 8551\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8552\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8553\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   8554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:777\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    776\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[0;32m--> 777\u001b[0m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    781\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    782\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:530\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    528\u001b[0m inferred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   inferred \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;66;03m# When converting a python object such as a list of Dimensions, we\u001b[39;00m\n\u001b[1;32m    534\u001b[0m   \u001b[38;5;66;03m# need a dtype to be specified, thus tensor conversion may throw\u001b[39;00m\n\u001b[1;32m    535\u001b[0m   \u001b[38;5;66;03m# an exception which we will ignore and try again below.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1636\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1627\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1628\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1629\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1633\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1636\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1639\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1589\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m inferred_dtype:\n\u001b[1;32m   1588\u001b[0m   v \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(_cast_nested_seqs_to_dtype(dtype), v)\n\u001b[0;32m-> 1589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_autopacking_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpacked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1525\u001b[0m, in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1520\u001b[0m       \u001b[38;5;66;03m# NOTE(mrry): This is inefficient, but it enables us to\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m       \u001b[38;5;66;03m# handle the case where the list arguments are other\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m       \u001b[38;5;66;03m# convertible-to-tensor types, such as numpy arrays.\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m       elems_as_tensors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m   1524\u001b[0m           constant_op\u001b[38;5;241m.\u001b[39mconstant(elem, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)))\n\u001b[0;32m-> 1525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43melems_as_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1527\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m converted_elems\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:6570\u001b[0m, in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6568\u001b[0m   axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   6569\u001b[0m axis \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_int(axis, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 6570\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6571\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6572\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   6573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    790\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    791\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    793\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    794\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3798\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3796\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3798\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3801\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3802\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3807\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2107\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m   2106\u001b[0m c_op \u001b[38;5;241m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[38;5;241m=\u001b[39mop_def)\n\u001b[0;32m-> 2107\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_from_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_op \u001b[38;5;241m=\u001b[39m original_op\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;66;03m# Post process for control flows.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2172\u001b[0m, in \u001b[0;36mOperation._init_from_c_op\u001b[0;34m(self, c_op, g)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;66;03m# Gradient function for this op. There are three ways to specify gradient\u001b[39;00m\n\u001b[1;32m   2166\u001b[0m \u001b[38;5;66;03m# function, and first available gradient gets used, in the following order.\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;66;03m# 1. self._gradient_function\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;66;03m# 2. Gradient name registered by \"_gradient_op_type\" attribute.\u001b[39;00m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;66;03m# 3. Gradient name registered by op.type.\u001b[39;00m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2172\u001b[0m op_def \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_op_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationOpType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_op\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stateful \u001b[38;5;241m=\u001b[39m op_def\u001b[38;5;241m.\u001b[39mis_stateful\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;66;03m# Initialize self._outputs.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4206\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4203\u001b[0m     pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GraphGetOpDef(c_graph, compat\u001b[38;5;241m.\u001b[39mas_bytes(\u001b[38;5;28mtype\u001b[39m),\n\u001b[1;32m   4204\u001b[0m                                        buf)\n\u001b[1;32m   4205\u001b[0m   data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n\u001b[0;32m-> 4206\u001b[0m op_def \u001b[38;5;241m=\u001b[39m \u001b[43mop_def_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4207\u001b[0m op_def\u001b[38;5;241m.\u001b[39mParseFromString(compat\u001b[38;5;241m.\u001b[39mas_bytes(data))\n\u001b[1;32m   4208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m op_def\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from ckiptagger import WS, POS, NER, construct_dictionary # tokenization\n",
    "\n",
    "# Setup work directory\n",
    "os.chdir('/Users/deankuo/Desktop/python/dissertation/Taiwan-Manifesto-Analysis-A-ML-Approach')\n",
    "os.listdir()\n",
    "\n",
    "# Import utils.py\n",
    "from Utils.utils_token import (\n",
    "    load_text,\n",
    "    split_content,\n",
    "    tokenization,\n",
    "    postprocess_dataframe,\n",
    "    \n",
    ")\n",
    "matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# CKIP module\n",
    "CKIP_PATH = \"../CKIP_TAGGER\"\n",
    "ws = WS(CKIP_PATH) # 斷詞\n",
    "pos = POS(CKIP_PATH) # 詞性標註\n",
    "ner = NER(CKIP_PATH) # 命名實體識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入自定義字典\n",
    "word_to_weight = {'823': 1, 'ECFA': 1, '2300': 1, '台26線': 1, '台74線': 1, '12年國教': 1, 'BOT': 1, '88快速道路': 1, '台27線': 1, '台61線': 1, '十二年國教': 1, '國道10號': 1,\n",
    "                  '台88號': 1, 'M型': 1, '205兵工廠': 1, '北二高': 1, '台65線': 1, 'CEPA': 1, 'FTA': 1, '科學園區': 1, '228': 1, 'MIT': 1, '202兵工廠': 1, '86快速道路': 1, '國道8號': 1,\n",
    "                  '台64': 1, '台66': 1, 'iBike': 1, 'MRT': 1, 'TPP': 1, 'TIFA': 1, 'TPP':1, '台22': 1, '台29': 1, '國10': 1, '國1': 1, '318': 1, 'NCC':1, 'PM2.5': 1, 'YouBike': 1, \n",
    "                  '台68': 1, '快速道路': 1, 'NGO': 1, 'NPO': 1, 'U-Bike': 1, 'LGBTQ': 1, '三七五減租': 1, '小三通': 1, '大三通': 1, '基礎建設': 1, '戒急用忍': 1, '社會役': 1, '非核家園': 1,\n",
    "                  '教育券': 1, '九二共識': 1}\n",
    "dictionary = construct_dictionary(word_to_weight)\n",
    "\n",
    "# 停用詞\n",
    "with open(\"./Data/stopwords_zh-tw.txt\", encoding=\"utf-8\") as fin:\n",
    "    stopwords = fin.read().split(\"\\n\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 17)\n",
      "(314, 17)\n",
      "(383, 17)\n",
      "(434, 17)\n",
      "(368, 17)\n",
      "(283, 17)\n",
      "(267, 17)\n",
      "(354, 17)\n",
      "(410, 17)\n",
      "(309, 17)\n"
     ]
    }
   ],
   "source": [
    "years = [1992, 1995, 1998, 2001, 2004, 2008, 2012, 2016, 2020, 2024]\n",
    "dfs = {}\n",
    "num = []\n",
    "for year in years:\n",
    "    dfs[year] = pd.read_excel(f\"./Data/merge_data/{year}.xlsx\")\n",
    "    print(dfs[year].shape)\n",
    "    num.append(dfs[year].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dfs.items():\n",
    "    dfs[k] = split_content(dfs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992 年的選舉共有 3970 筆資料\n",
      "1992 年選舉的候選人平均提出 12.03 筆政見\n",
      "\n",
      "1995 年的選舉共有 3580 筆資料\n",
      "1995 年選舉的候選人平均提出 11.4 筆政見\n",
      "\n",
      "1998 年的選舉共有 4332 筆資料\n",
      "1998 年選舉的候選人平均提出 11.31 筆政見\n",
      "\n",
      "2001 年的選舉共有 4647 筆資料\n",
      "2001 年選舉的候選人平均提出 10.71 筆政見\n",
      "\n",
      "2004 年的選舉共有 3926 筆資料\n",
      "2004 年選舉的候選人平均提出 10.67 筆政見\n",
      "\n",
      "2008 年的選舉共有 3724 筆資料\n",
      "2008 年選舉的候選人平均提出 13.16 筆政見\n",
      "\n",
      "2012 年的選舉共有 2917 筆資料\n",
      "2012 年選舉的候選人平均提出 10.93 筆政見\n",
      "\n",
      "2016 年的選舉共有 3918 筆資料\n",
      "2016 年選舉的候選人平均提出 11.07 筆政見\n",
      "\n",
      "2020 年的選舉共有 4797 筆資料\n",
      "2020 年選舉的候選人平均提出 11.7 筆政見\n",
      "\n",
      "2024 年的選舉共有 3744 筆資料\n",
      "2024 年選舉的候選人平均提出 12.12 筆政見\n",
      "\n",
      "一共有 39555 筆資料\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "n = 0\n",
    "for k, v in dfs.items():\n",
    "    t = v.shape[0]\n",
    "    sum += t\n",
    "    print(f\"{k} 年的選舉共有 {t} 筆資料\")\n",
    "    print(f\"{k} 年選舉的候選人平均提出 {round(t / num[n], 2)} 筆政見\\n\")\n",
    "    n += 1\n",
    "print(f\"一共有 {sum} 筆資料\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\n",
      "原文：\n",
      "５、青年＆就業︰規劃吸引年輕人返鄉就業，本區應制定在地廠商聘用本區或外地的年輕人之相關優惠的補助條件和方式，讓年輕人願意留在本區務農、就業、甚至創業。\n",
      "斷詞後：\n",
      "青年 就業 規劃 吸引 年輕人 返鄉 就業 制定 在地 廠商 聘用 外地 年輕人 相關 優惠 補助 條件 方式 年輕人 願意 留在 務農 就業 甚至 創業\n",
      "斷詞後+詞性標注：\n",
      "['青年(Na)', '就業(VA)', '規劃(VC)', '吸引(VJ)', '年輕人(Na)', '返鄉(VA)', '就業(VA)', '制定(VC)', '在地(A)', '廠商(Na)', '聘用(VC)', '外地(Nc)', '年輕人(Na)', '相關(VH)', '優惠(VJ)', '補助(Nv)', '條件(Na)', '方式(Na)', '年輕人(Na)', '願意(VK)', '留在(VCL)', '務農(VA)', '就業(VA)', '創業(VA)']\n",
      "透過詞性篩選的斷詞: \n",
      "青年 就業 規劃 吸引 年輕人 返鄉 就業 制定 在地 廠商 聘用 外地 年輕人 相關 優惠 補助 條件 方式 年輕人 願意 留在 務農 就業 創業\n",
      "命名實體辨識: \n",
      "[{(0, 1, 'CARDINAL', '５')}]\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "# Test the text selection function\n",
    "text = dfs[2024].loc[250, 'CONTENT']\n",
    "\n",
    "sentence_, pos_, ner_, token_ = load_text(text, test=1)\n",
    "print()\n",
    "print('=====')\n",
    "print(\"原文：\")\n",
    "print(text)\n",
    "print(\"斷詞後：\")\n",
    "print(sentence_)\n",
    "print(\"斷詞後+詞性標注：\")\n",
    "print(pos_)\n",
    "print(\"透過詞性篩選的斷詞: \")\n",
    "print(token_)\n",
    "print(\"命名實體辨識: \")\n",
    "print(ner_)\n",
    "print('=====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate Each Year Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d5efbe95c247d3bb392ac6ee465482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 1992 election statements:   0%|          | 0/3970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992年選舉公報的斷詞運算時間為: 8.94 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dad6348bfe40ecbc7a7c81e00792ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 1995 election statements:   0%|          | 0/3580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995年選舉公報的斷詞運算時間為: 6.78 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04262b331154df39e8b13c703cef506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 1998 election statements:   0%|          | 0/4332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998年選舉公報的斷詞運算時間為: 8.9 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e91656afe54a25a119bf0641228abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2001 election statements:   0%|          | 0/4647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001年選舉公報的斷詞運算時間為: 8.49 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbff0e803fb4c2891ea929d3585ccc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2004 election statements:   0%|          | 0/3926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004年選舉公報的斷詞運算時間為: 7.14 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7d1a2e8f6a4bd1a9af1314a12bedf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2008 election statements:   0%|          | 0/3724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008年選舉公報的斷詞運算時間為: 6.99 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b792d366b9449eb83fbf6fb360f1146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2012 election statements:   0%|          | 0/2917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012年選舉公報的斷詞運算時間為: 26.85 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d81544fc3c4c4b9528ceda88eee4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2016 election statements:   0%|          | 0/3918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016年選舉公報的斷詞運算時間為: 7.92 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1696e32026414d9cc584fd83962ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2020 election statements:   0%|          | 0/4797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020年選舉公報的斷詞運算時間為: 8.59 分\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe43d86e9d56401ea01148239a38d40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing 2024 election statements:   0%|          | 0/3744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024年選舉公報的斷詞運算時間為: 7.1 分\n"
     ]
    }
   ],
   "source": [
    "for key, value in dfs.items():\n",
    "    dfs[key] = tokenization(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1992, 1995, 1998, 2001, 2004, 2008, 2012, 2016, 2020, 2024]\n",
    "dfs = {}\n",
    "for year in years:\n",
    "    dfs[year] = pd.read_csv(f\"./Data/Dataset/{year}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dfs.items():\n",
    "    dfs[k] = postprocess_dataframe(dfs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39535\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for k, v in dfs.items():\n",
    "    sum += dfs[k].shape[0]\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dfs.items():\n",
    "    dfs[k].to_csv(f'./Data/Dataset/{k}.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(dfs.values(), ignore_index=True)\n",
    "combined_df.to_csv('./Data/Manifesto_Dataset.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
